{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import os\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "class SVM():\n",
    "    \"\"\"\n",
    "        Simple implementation of a Support Vector Machine using the\n",
    "        Sequential Minimal Optimization (SMO) algorithm for training.\n",
    "    \"\"\"\n",
    "    def __init__(self, max_iter=100, kernel_type='linear', C=1.0, epsilon=0.001):\n",
    "        self.kernels = {\n",
    "            'linear' : self.kernel_linear,\n",
    "            'quadratic' : self.kernel_quadratic\n",
    "        }\n",
    "        self.max_iter = max_iter\n",
    "        self.kernel_type = kernel_type\n",
    "        self.C = C\n",
    "        self.epsilon = epsilon\n",
    "    def fit(self, X, y):\n",
    "        # Initialization\n",
    "        n, d = X.shape[0], X.shape[1]\n",
    "        alpha = np.zeros((n))\n",
    "        kernel = self.kernels[self.kernel_type]\n",
    "        count = 0\n",
    "        while True:\n",
    "            count += 1\n",
    "            alpha_prev = np.copy(alpha)\n",
    "            for j in range(0, n):\n",
    "                i = self.get_rnd_int(0, n-1, j) # Get random int i~=j\n",
    "                x_i, x_j, y_i, y_j = X[i,:], X[j,:], y[i], y[j]\n",
    "                k_ij = kernel(x_i, x_i) + kernel(x_j, x_j) - 2 * kernel(x_i, x_j)\n",
    "                if k_ij == 0:\n",
    "                    continue\n",
    "                alpha_prime_j, alpha_prime_i = alpha[j], alpha[i]\n",
    "                (L, H) = self.compute_L_H(self.C, alpha_prime_j, alpha_prime_i, y_j, y_i)\n",
    "\n",
    "                # Compute model parameters\n",
    "                self.w = self.calc_w(alpha, y, X)\n",
    "                self.b = self.calc_b(X, y, self.w)\n",
    "\n",
    "                # Compute E_i, E_j\n",
    "                E_i = self.E(x_i, y_i, self.w, self.b)\n",
    "                E_j = self.E(x_j, y_j, self.w, self.b)\n",
    "\n",
    "                # Set new alpha values\n",
    "                alpha[j] = alpha_prime_j + float(y_j * (E_i - E_j))/k_ij\n",
    "                alpha[j] = max(alpha[j], L)\n",
    "                alpha[j] = min(alpha[j], H)\n",
    "\n",
    "                alpha[i] = alpha_prime_i + y_i*y_j * (alpha_prime_j - alpha[j])\n",
    "\n",
    "            # Check convergence\n",
    "            diff = np.linalg.norm(alpha - alpha_prev)\n",
    "            if diff < self.epsilon:\n",
    "                break\n",
    "\n",
    "            if count >= self.max_iter:\n",
    "                print(\"Iteration number exceeded the max of %d iterations\" % (self.max_iter))\n",
    "                return\n",
    "        # Compute final model parameters\n",
    "        self.b = self.calc_b(X, y, self.w)\n",
    "        if self.kernel_type == 'linear':\n",
    "            self.w = self.calc_w(alpha, y, X)\n",
    "        # Get support vectors\n",
    "        alpha_idx = np.where(alpha > 0)[0]\n",
    "        support_vectors = X[alpha_idx, :]\n",
    "        return support_vectors, count\n",
    "    def predict(self, X):\n",
    "        return self.h(X, self.w, self.b)\n",
    "    def calc_b(self, X, y, w):\n",
    "        b_tmp = y - np.dot(w.T, X.T)\n",
    "        return np.mean(b_tmp)\n",
    "    def calc_w(self, alpha, y, X):\n",
    "        return np.dot(X.T, np.multiply(alpha,y))\n",
    "    # Prediction\n",
    "    def h(self, X, w, b):\n",
    "        return np.sign(np.dot(w.T, X.T) + b).astype(int)\n",
    "    # Prediction error\n",
    "    def E(self, x_k, y_k, w, b):\n",
    "        return self.h(x_k, w, b) - y_k\n",
    "    def compute_L_H(self, C, alpha_prime_j, alpha_prime_i, y_j, y_i):\n",
    "        if(y_i != y_j):\n",
    "            return (max(0, alpha_prime_j - alpha_prime_i), min(C, C - alpha_prime_i + alpha_prime_j))\n",
    "        else:\n",
    "            return (max(0, alpha_prime_i + alpha_prime_j - C), min(C, alpha_prime_i + alpha_prime_j))\n",
    "    def get_rnd_int(self, a,b,z):\n",
    "        i = z\n",
    "        cnt=0\n",
    "        while i == z and cnt<1000:\n",
    "            i = rnd.randint(a,b)\n",
    "            cnt=cnt+1\n",
    "        return i\n",
    "    # Define kernels\n",
    "    def kernel_linear(self, x1, x2):\n",
    "        return np.dot(x1, x2.T)\n",
    "    def kernel_quadratic(self, x1, x2):\n",
    "        return (np.dot(x1, x2.T) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv(\"mnist_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_required=data[(data['label']!=3) & (data['label']!=8)]\n",
    "data=data.drop(not_required.index, axis=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=data['label']\n",
    "data=data.drop(['label'], axis=1)\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n=len(data)\n",
    "X_train=data[:int(0.6*n)]\n",
    "Y_train=labels[:int(0.6*n)]\n",
    "X_val=data[int(0.6*n):int(0.8*n)]\n",
    "Y_val=labels[int(0.6*n):int(0.8*n)]\n",
    "X_test=data[int(0.8*n):]\n",
    "Y_test=labels[int(0.8*n):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_acc(y, y_hat):\n",
    "    idx = np.where(y_hat == 1)\n",
    "    TP = np.sum(y_hat[idx] == y[idx])\n",
    "    idx = np.where(y_hat == -1)\n",
    "    TN = np.sum(y_hat[idx] == y[idx])\n",
    "    return float(TP + TN)/len(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVM()\n",
    "X_train=np.array(X_train)\n",
    "Y_train=np.array(Y_train)\n",
    "X_test=np.array(X_test)\n",
    "Y_test=np.array(Y_test)\n",
    "support_vectors, iterations = model.fit(X_train, Y_train)\n",
    "sv_count = support_vectors.shape[0]\n",
    "Y_pred = model.predict(X_test)\n",
    "acc = calc_acc(Y_test, Y_pred)\n",
    "\n",
    "print(\"Support vector count: %d\" % (sv_count))\n",
    "print(\"bias:\\t\\t%.3f\" % (model.b))\n",
    "print(\"w:\\t\\t\" + str(model.w))\n",
    "print(\"accuracy:\\t%.3f\" % (acc))\n",
    "print(\"Converged after %d iterations\" % (iterations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
